{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from sklearn_porter import Porter\n",
    "import json\n",
    "from json import encoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer, FeatureHasher\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "p = Path('data')\n",
    "for datafile in p.iterdir():\n",
    "    with datafile.open('r') as f:\n",
    "        d = json.load(f)\n",
    "        data[d['name']] = d['dataPoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pipeline(clf=None):\n",
    "    if clf is None:\n",
    "        clf = RandomForestClassifier(n_estimators=200,\n",
    "                                     oob_score=True,\n",
    "                                     max_depth=None,\n",
    "                                     min_samples_split=2,\n",
    "                                     max_features='auto')\n",
    "    return make_pipeline(DictVectorizer(sparse=False), clf)\n",
    "\n",
    "def format_training_data(data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for name, room in data.items():\n",
    "        X.extend([aps_to_dict(data_point) for data_point in room])\n",
    "        y.extend([name] * len(room))\n",
    "    return X, y\n",
    "\n",
    "def aps_to_dict(aps):\n",
    "    return {ap['mac']: ap['rssi'] for ap in aps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dictvectorizer',\n",
       "  DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "          sparse=False)),\n",
       " ('randomforestclassifier',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "              oob_score=True, random_state=None, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline = get_pipeline(clf=MLPClassifier(alpha=1, solver='lbfgs'))\n",
    "# pipeline = get_pipeline(clf=AdaBoostClassifier(base_estimator=RandomForestClassifier(n_estimators=100,\n",
    "#                                                                                      oob_score=True,\n",
    "#                                                                                      max_depth=None,\n",
    "#                                                                                      min_samples_split=2,\n",
    "#                                                                                      max_features='sqrt'),\n",
    "#                                                                                      n_estimators=200))\n",
    "pipeline = get_pipeline()\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 401 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X, y = format_training_data(data)\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.09)\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X, y = format_training_data(data)\n",
    "scores = cross_val_score(pipeline, X, y)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__n_estimators': 20}\n",
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = { \n",
    "    'randomforestclassifier__n_estimators': [20, 30, 40, 50, 75, 100, 150, 200],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "cv = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=20, n_jobs=-1)\n",
    "X, y = format_training_data(data)\n",
    "cv.fit(X, y)\n",
    "best = cv.best_estimator_\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(best, X, y)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "porter = Porter(pipeline, language='java')\n",
    "output = porter.export(method='predict', export_data=True)\n",
    "with open('data.json', 'r') as f:\n",
    "    out = json.load(f)\n",
    "out = {\n",
    "    'features': pipeline.steps[0][1].get_feature_names(),\n",
    "    'classes': list(pipeline._final_estimator.classes_),\n",
    "    'forest': out\n",
    "}\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(out, f, separators=(',', ':'))\n",
    "# print(output) # Show java source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
